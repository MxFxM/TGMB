{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TGMB_Bee_Detection.ipynb","private_outputs":true,"provenance":[{"file_id":"https://github.com/luxonis/depthai-ml-training/blob/master/colab-notebooks/Easy_Object_Detection_Demo_Training.ipynb","timestamp":1616697584349}],"collapsed_sections":["3qucQJwsWhL3"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"zIhYNF3zZQqK"},"source":["# DepthAI Object Detection Tutorial\n","\n","<img src=\"https://docs.luxonis.com/images/depthai_logo.png\" width=\"500\">\n","\n","Welcome to DepthAI! \n","\n","In this tutorial we will go through the basic training of an object detection model. The model will be trained to recognize 3 fruits: apples, bananas and oranges.\n","\n","The model is a pretrained Mobilenet SSD v2 from the Tensorflow Object Detection API model zoo. The framework used for training is TensorFlow 1.15.2.\n","Will run through the following steps:\n","\n","\n","*   Install the libraries\n","*   Clone the github repo with the training data(images)\n","*   Train the model on the new images\n","*   Run inference on a few images to see what the model can detect\n","*   As an optional step, convert the model for OpenVINO inference\n","\n","You can make a copy of this tutorial: File-> Save a copy in Drive\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"p77QHgKKtdDm"},"source":["while True:\n","    pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yhzxsJb3dpWq"},"source":["# Install Libraries\n","# Press Shift+Enter to run cells\n","Some cells are commented out (all text is green), so they will not run the code inside.\n","To uncomment code inside a cell, select all the code then press Ctrl + /"]},{"cell_type":"code","metadata":{"id":"pH1x08R-yM-L"},"source":["# %%capture\n","#After this cell executes runtime will restart, ignore the crash message, continue running cells starting with the one below\n","!pip install numpy==1.17.5;\n","# !pip install tensorflow-gpu==1.15.0;\n","import os\n","os.kill(os.getpid(), 9)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9z8kgcs0E7iV"},"source":["%tensorflow_version 1.x\n","!pip install tf_slim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gnNXNQCjdniL"},"source":["# For the fruit model included in the repo below we have 240 training images\n","# For faster training time, images should be resized to 300x300 and then annotated\n","# Images should contain the objects of interest at various scales, angles, lighting conditions, locations\n","# For acceptable results - mAP@0.5 of 0.9 the model was trained with batch size of 24\n","# and 5000 steps. this takes about 1h using 2 augmentations. \n","# using 5 augmentations it takes about 2h \n","num_steps = 10000 #1000 # A step means using a single batch of data. larger batch, less steps required\n","#Number of evaluation steps.\n","num_eval_steps = 50\n","#Batch size 24 is a setting that generally works well. can be changed higher or lower \n","MODELS_CONFIG = {\n","        'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n","        'batch_size': 32 #24\n","    },\n","        'ssd_resnet_50': {\n","        'model_name': 'ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03',\n","        'pipeline_file': 'ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync.config',\n","        'batch_size': 8\n","    },\n","        'ssd_inception_v2': {\n","        'model_name': 'ssd_inception_v2_coco_2018_01_28',\n","        'pipeline_file': 'ssd_inception_v2_coco.config',\n","        'batch_size': 32\n","    }\n","}\n","#selected_model = 'ssd_mobilenet_v2'\n","#selected_model = 'ssd_resnet_50'\n","selected_model = 'ssd_inception_v2'\n","\n","# Name of the object detection model to use.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","# Name of the pipline file in tensorflow object detection API.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","# Training batch size fits in Colab's GPU memory for selected model.\n","batch_size = MODELS_CONFIG[selected_model]['batch_size']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w4V-XE6kbkc1"},"source":["## Clone the `object_detection_demo_flow` repository"]},{"cell_type":"code","metadata":{"id":"dxc3DmvLQF3z"},"source":["repo_url = 'https://github.com/GotG/object_detection_demo_flow'\n","import os\n","%cd /content\n","repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n","!git clone {repo_url}\n","%cd {repo_dir_path}\n","!git pull"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pHUcVDSEfuCE"},"source":["# #quick check for training data files\n","# !ls /content/object_detection_demo_flow/data/images/train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sp0iUavswF9I"},"source":["from google.colab import files\n","\n","%cd /content\n","print(\"Upload the allimages.zip file\")\n","files.upload()\n","\n","!unzip allimages.zip -d ./allimages"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rbvx6X-PyNzv"},"source":["%cd /content\n","\n","# clear original images\n","!rm object_detection_demo_flow/test/*\n","!rm object_detection_demo_flow/data/images/train/*\n","!rm object_detection_demo_flow/data/images/test/*\n","!rm object_detection_demo_flow/data/images/final_test/*\n","\n","# instead, copy my images :D\n","!cp allimages/* object_detection_demo_flow/data/images/train/\n","!cp allimages/* object_detection_demo_flow/data/images/test/\n","!cp allimages/* object_detection_demo_flow/data/images/final_test/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HgG6aaafDfio"},"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VKojaxH3D2gU"},"source":["\"\"\"\n","%cd /content\n","\n","# clear original images\n","!rm object_detection_demo_flow/test/*\n","!rm object_detection_demo_flow/data/images/train/*\n","!rm object_detection_demo_flow/data/images/test/*\n","!rm object_detection_demo_flow/data/images/final_test/*\n","\n","!mkdir allimages\n","\n","import glob, os\n","from shutil import copyfile\n","os.chdir(\"/content/gdrive/MyDrive/TGMB/datasets/to-bee-or-not-to-bee/labels\")\n","for file in glob.glob(\"*.xml\"):\n","    #print(file)\n","    copyfile(f\"/content/gdrive/MyDrive/TGMB/datasets/to-bee-or-not-to-bee/allimages/{file[:-4]}.jpg\", f\"/content/allimages/{file[:-4]}.jpg\")\n","!cp /content/gdrive/MyDrive/TGMB/datasets/to-bee-or-not-to-bee/labels/* /content/allimages/\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"viUNOPQaGTrL"},"source":["\"\"\"\n","%cd /content\n","!mkdir /content/gdrive/MyDrive/TGMB/datasets/to-bee-or-not-to-bee/1000images\n","\n","# instead, copy my images :D\n","!cp allimages/* object_detection_demo_flow/data/images/train/\n","!cp allimages/* object_detection_demo_flow/data/images/test/\n","!cp allimages/* object_detection_demo_flow/data/images/final_test/\n","!cp allimages/* /content/gdrive/MyDrive/TGMB/datasets/to-bee-or-not-to-bee/1000images/\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kWvuI15XHZ2c"},"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")\n","\n","%cd /content\n","!mkdir allimages\n","!cp /content/gdrive/MyDrive/TGMB/datasets/to-bee-or-not-to-bee/1000images/* /content/allimages/\n","\n","# clear original images\n","!rm object_detection_demo_flow/test/*\n","!rm object_detection_demo_flow/data/images/train/*\n","!rm object_detection_demo_flow/data/images/test/*\n","!rm object_detection_demo_flow/data/images/final_test/*\n","\n","# instead, copy my images :D\n","!cp allimages/* object_detection_demo_flow/data/images/train/\n","!cp allimages/* object_detection_demo_flow/data/images/test/\n","!cp allimages/* object_detection_demo_flow/data/images/final_test/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bI8__uNS8-ns"},"source":["## Clone TF models which contains the Object Detection API; also install the required dependencies\n"]},{"cell_type":"code","metadata":{"id":"ecpHEnka8Kix"},"source":["%%capture\n","%cd /content\n","!git clone --quiet https://github.com/tensorflow/models.git\n","%cd /content/models/\n","!git checkout 58d19c67e1d30d905dd5c6e5092348658fed80af\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n","!pip install -q Cython contextlib2 pillow lxml matplotlib\n","!pip install -q pycocotools\n","%cd /content/models/research\n","!protoc object_detection/protos/*.proto --python_out=.\n","import os\n","os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n","!python object_detection/builders/model_builder_test.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u-k7uGThXlny"},"source":["## Prepare `tfrecord` files\n","\n"]},{"cell_type":"code","metadata":{"id":"ezGDABRXXhPP"},"source":["%%capture\n","%cd {repo_dir_path}\n","\n","# Convert train folder annotation xml files to a single csv file,\n","# generate the `label_map.pbtxt` file to `data/` directory as well.\n","!python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n","\n","# Convert test folder annotation xml files to a single csv.\n","!python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n","\n","# Generate `train.record`\n","!python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n","\n","# Generate `test.record`\n","!python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tgd-fzAIkZlV"},"source":["test_record_fname = '/content/object_detection_demo_flow/data/annotations/test.record'\n","train_record_fname = '/content/object_detection_demo_flow/data/annotations/train.record'\n","label_map_pbtxt_fname = '/content/object_detection_demo_flow/data/annotations/label_map.pbtxt'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iCNYAaC7w6N8"},"source":["## Download the (Mobilenet SSD v2) Model"]},{"cell_type":"code","metadata":{"id":"orDCj6ihgUMR"},"source":["%cd /content/models/research\n","\n","import os\n","import shutil\n","import glob\n","import urllib.request\n","import tarfile\n","MODEL_FILE = MODEL + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","DEST_DIR = '/content/models/research/pretrained_model'\n","\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","    shutil.rmtree(DEST_DIR)\n","os.rename(MODEL, DEST_DIR)\n","!echo {DEST_DIR}\n","!ls -alh {DEST_DIR}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UHnxlfRznPP3"},"source":["#TF pretrained model checkpoint\n","fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n","fine_tune_checkpoint"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MvwtHlLOeRJD"},"source":["## Configuring a Training Pipeline"]},{"cell_type":"code","metadata":{"id":"dIhw7IdpLuiU"},"source":["import os\n","pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n","\n","assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)\n","def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EFMJBsTbcCcp"},"source":["if selected_model == 'ssd_resnet_50':\n","    print(\"Upload ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync.config now\")\n","    from google.colab import files\n","    files.upload()\n","    !cp /content/models/research/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync.config /content/models/research/object_detection/samples/configs/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync.config\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YjtCbLF2i0wI"},"source":["import re\n","iou_threshold = 0.50\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open(pipeline_fname, 'w') as f:\n","    \n","    # fine_tune_checkpoint\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # tfrecord files train and test.\n","    s = re.sub(\n","        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    # Set number of classes num_classes.\n","    s = re.sub('iou_threshold: [0-9].[0-9]+',\n","               'iou_threshold: {}'.format(iou_threshold), s)\n","    \n","    f.write(s)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GH0MEEanocn6"},"source":["# #Have a look at the config file with various settings\n","#!cat {pipeline_fname}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jP-hxSKvdwsA"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JDddx2rPfex9"},"source":["# Train the model"]},{"cell_type":"markdown","metadata":{"id":"j5rinKkEe5ut"},"source":["##[Optional] The cell below adds Tensorboard visualization to the training process. \n","Will open in new tab."]},{"cell_type":"code","metadata":{"id":"f11w0uO3jFCB"},"source":["#After running this cell click on the link in the output cell to open tensorboard\n","#Tensoarboard will show you graphically different training parameters as the model is training\n","#when training finishes after the set number of steps, tensorboard can be used to see a nice summary of the training process\n","#Visuals will load in Tensorboard after the model has gone through a few hundred steps\n","model_dir = 'training/'\n","!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip ngrok-stable-linux-amd64.zip\n","LOG_DIR = model_dir\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")\n","get_ipython().system_raw('./ngrok http 6006 &')\n","! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kfjw6q-3wP62"},"source":["## Start the training"]},{"cell_type":"code","metadata":{"id":"CjDHjhKQofT5"},"source":["# note that training is stored in /content/models/research/training/\n","model_dir = 'training/'\n","\n","# Optionally remove content in output model directory for a fresh start.\n","# !rm -rf {model_dir}\n","# os.makedirs(model_dir, exist_ok=True)\n","!python -W ignore /content/models/research/object_detection/model_main.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --num_eval_steps={num_eval_steps}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KP-tUdtnRybs"},"source":["#model dir check for the trained model\n","!ls {model_dir}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OmSESMetj1sa"},"source":["## Export a Trained Inference Graph\n","Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"]},{"cell_type":"code","metadata":{"id":"zZJ_AF5MD3hZ"},"source":["#clean output_directory if necessary to start fresh:\n","\n","# !rm -rf /content/object_detection_demo/fine_tuned_model/ \n","# os.makedirs('/content/object_detection_demo_flow/fine_tuned_model/', exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DHoP90pUyKSq"},"source":["%%capture\n","import re\n","import numpy as np\n","\n","output_directory = './fine_tuned_model'\n","# output_directory = '/content/gdrive/My\\ Drive/data/'\n","\n","lst = os.listdir(model_dir)\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","last_model = lst[steps.argmax()].replace('.meta', '')\n","\n","last_model_path = os.path.join(model_dir, last_model)\n","print(last_model_path)\n","!python /content/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --output_directory={output_directory} \\\n","    --trained_checkpoint_prefix={last_model_path}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"usgBZvkz0nqD"},"source":["#export directory check\n","# !ls {output_directory}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CnDo1lonKgFr"},"source":["import os\n","pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n","assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)\n","# !ls -alh {pb_fname}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3qucQJwsWhL3"},"source":["# Prepare the TF model for DepthAI. \n","# First, we convert the model to OpenVINO 20.01 Intermediate Representation (IR)\n","(This can be used to run inference on OpenVINO, but for our purpose it is only a step in the preparation for DepthAI)\n","# In order to run the model on DepthAI modules, we then compile the IR obtained above to a .blob (via a server we set up just for that) "]},{"cell_type":"markdown","metadata":{"id":"-pHw4l-gNZ4P"},"source":["## Install OpenVINO 20.01\n"]},{"cell_type":"code","metadata":{"id":"5py5tfxS6VaA"},"source":["%%time\n","%%capture\n","## install tools. Open Vino takes some time to download: 10-15 min sometimes.\n","!sudo apt-get install -y pciutils cpio\n","!sudo apt autoremove\n","## download installation files\n","!wget http://registrationcenter-download.intel.com/akdlm/irc_nas/16345/l_openvino_toolkit_p_2020.1.023.tgz\n","path = \"l_openvino_toolkit_p_2020.1.023.tgz\"\n","# path = \"/content/software/Intel OpenVINO 2019 R3.1/l_openvino_toolkit_p_2019.3.376.tgz\"\n","## install openvino\n","!tar xf \"{path}\"\n","%cd l_openvino_toolkit_p_2020.1.023/\n","!./install_openvino_dependencies.sh && \\\n","    sed -i 's/decline/accept/g' silent.cfg && \\\n","    ./install.sh --silent silent.cfg"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h-jbjiw-7nAv"},"source":["OpenVINO install check"]},{"cell_type":"code","metadata":{"id":"0NJp28Oj7Ts9"},"source":["# !source /opt/intel/openvino/bin/setupvars.sh && \\\n","#     /opt/intel/openvino/deployment_tools/demo/demo_squeezenet_download_convert_run.sh"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P-bGZHGcMNbZ"},"source":["%cd /opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/\n","#openvino fixes: edit \n","# Read in the file, make sure the .json corresponds to the model!!!\n","with open('ssd_v2_support.json', 'r') as file :\n","  filedata = file.read()\n","\n","# Replace the target string\n","filedata = filedata.replace('\"Postprocessor/ToFloat\"', '\"Postprocessor/Cast_1\"')\n","\n","# Write the file out again\n","with open('ssd_v2_support.json', 'w') as file:\n","  file.write(filedata)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R7sqTX79W6hh"},"source":["## Convert TF model to OpenVINO IR"]},{"cell_type":"code","metadata":{"id":"LsWggE5AIWS6"},"source":["#CONVERT TF MODEL to OPEN VINO IRv10. saved in IRv10 directory or choose name\n","%cd \"/content/models/research/fine_tuned_model/\"\n","!source /opt/intel/openvino/bin/setupvars.sh && \\\n","    python /opt/intel/openvino/deployment_tools/model_optimizer/mo.py \\\n","    --input_model frozen_inference_graph.pb \\\n","    --tensorflow_use_custom_operations_config /opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json \\\n","    --tensorflow_object_detection_api_pipeline_config pipeline.config \\\n","    --reverse_input_channels \\\n","    --output_dir ./IR_V10_fruits_mnssdv2_6k \\\n","    --data_type FP16  \n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UzArRZOALo_6"},"source":["## We compile the IR model to a .blob for use on DepthAI modules/platform\n","We save the blob in the IR directory from above, corresponding to --output_dir parameter above.\n","\n","The blob filename will be frozen_inference_graph.blob"]},{"cell_type":"code","metadata":{"id":"rUYtu18IMFoP"},"source":["#No changes needed here unless using custom data.\n","#CHOOSE the directory where you would like to save the blob.\n","# I use the same --output_dir as above for the IR conversion\n","blob_dir = \"/content/models/research/fine_tuned_model/IR_V10_fruits_mnssdv2_6k/\"\n","\n","#Copy the path of your .xml and .bin files. For that, you can look at the IR\n","#conversion output cell, select and copy from:\n","#[SUCCESS] XML file and bin file paths.\n","#Or you can choose to compile other .xml .bin files from a different location\n","#\n","xmlfile = \"/content/models/research/fine_tuned_model/./IR_V10_fruits_mnssdv2_6k/frozen_inference_graph.xml\"\n","binfile = \"/content/models/research/fine_tuned_model/./IR_V10_fruits_mnssdv2_6k/frozen_inference_graph.bin\"\n","\n","import requests\n","\n","#For openvino 20.01 use this link to compile the blobb\n","url = \"http://69.164.214.171:8080\"\n","\n","\n","#open vino 20.02 link:\n","# url = \"69.164.214.171:8081\"\n","\n","#payload = {'compiler_params': '-ip U8 -VPU_MYRIAD_PLATFORM VPU_MYRIAD_2480 -VPU_NUMBER_OF_SHAVES 4 -VPU_NUMBER_OF_CMX_SLICES 4'}\n","payload = {'compiler_params': '-ip U8 -VPU_MYRIAD_PLATFORM VPU_MYRIAD_2480 -VPU_NUMBER_OF_SHAVES 8 -VPU_NUMBER_OF_CMX_SLICES 8'}\n","files = [\n","  ('definition', open(xmlfile,'rb')),\n","  ('weights', open(binfile,'rb'))\n","]\n","# headers = {\n","#   'Content-Type': 'application/json'\n","# }\n","response = requests.request(\"POST\", url, data = payload, files = files)\n","blobnameraw = response.headers.get('Content-Disposition')\n","blobname = blobnameraw[blobnameraw.find('='):][1:]\n","with open(blob_dir + blobname, 'wb') as f:\n","  f.write(response.content)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gjcjk9TGMOxq"},"source":["##Now you can download your .blob file and run it on the DepthAI module/platform\n","To download locally, use the file explorer on the left to locate the file in the --output_dir folder, then right click download. Colab takes a few seconds to prepare the file, then the download prompt will appear."]},{"cell_type":"markdown","metadata":{"id":"gVo0ZZF3f1dn"},"source":["## To run the .blob in DepthAI, follow the tutorial:\n","https://docs.luxonis.com/en/latest/pages/tutorials/hello_world/\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6YH94kNkM5Uk"},"source":["[Optional] to convert the blob locally, download the IR files .bin and .xml and follow these instructions:\n","\n","https://docs.luxonis.com/en/latest/pages/tutorials/local_convert_openvino/"]},{"cell_type":"code","metadata":{"id":"GOBXTQGqMgH0"},"source":["#compress the IR_V10 folder. it is in content/models/research/fine_tuned_model\n","!tar cvf IR_V10_fruits_mnssdv2_6k.tar.gz IR_V10_fruits_mnssdv2_6k\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NLzHC-E9Mo6v"},"source":["#download the compressed IRv10 folder locally\n","#or can use file navigator on the left to move it to your gdrive\n","from google.colab import files\n","files.download(\"IR_V10_fruits_mnssdv2_6k\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Wu5za9YFhQa"},"source":["\n","\n","```\n","# This is formatted as code\n","```\n","\n","# Intel OpenVINO toolkit Installation and Validations 2021"]},{"cell_type":"code","metadata":{"id":"i8Ck5LpKhBil"},"source":["!cd /content"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fk0YYXXdFzPj"},"source":["print(\"This will take a while...\")\n","!wget -O openvino_key https://apt.repos.intel.com/openvino/2021/GPG-PUB-KEY-INTEL-OPENVINO-2021?elq_cid=6770273_ts1607381885691&erpm_id=9830841_ts1607381885691&elq_cid=6770273_ts1607381960247&erpm_id=9830841_ts1607381960247 \n","!apt-key add openvino_key\n","#!apt-key -q list\n","!echo \"deb https://apt.repos.intel.com/openvino/2021 all main\" | tee /etc/apt/sources.list.d/intel-openvino-2021.list\n","!apt update -q\n","!apt-cache search intel-openvino-dev-ubuntu18\n","!apt-get install intel-openvino-dev-ubuntu18-2021.2.200 -y -q\n","!pip install -U --no-deps --quiet openvino\n","\n","#unknown bug - this is just a patch\n","!cp /opt/intel/openvino_2021/deployment_tools/inference_engine/external/tbb/lib/libtbb.so /usr/lib/x86_64-linux-gnu/libtbb.so\n","!cp /opt/intel/openvino_2021/deployment_tools/inference_engine/external/tbb/lib/libtbb.so.2 /usr/lib/x86_64-linux-gnu/libtbb.so.2\n","!ldconfig\n","print(\"Installation Completed...\")\n","#%env we can set environmental variable with this\n","\n","#Run the validation\n","!ls /opt/intel/\n","#Run the Validation Demo code.\n","demo_cmd = \"/opt/intel/openvino_2021/deployment_tools/demo/demo_squeezenet_download_convert_run.sh\"\n","import os\n","import subprocess\n","import shutil\n","output = subprocess.check_output(demo_cmd, shell=True)\n","print (output.decode('utf-8'))     "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b5Z1QFooGIW8"},"source":["## Convert to OpenVINO IR format"]},{"cell_type":"markdown","metadata":{"id":"WOAq4lZZiIA7"},"source":["### Old option (do not use?!)"]},{"cell_type":"code","metadata":{"id":"fBE-3yfciGgN"},"source":["%cd /opt/intel/openvino_2021/deployment_tools/model_optimizer/extensions/front/tf/\n","#openvino fixes: edit \n","# Read in the file, make sure the .json corresponds to the model!!!\n","with open('ssd_v2_support.json', 'r') as file :\n","  filedata = file.read()\n","\n","# Replace the target string\n","filedata = filedata.replace('\"Postprocessor/ToFloat\"', '\"Postprocessor/Cast_1\"')\n","\n","# Write the file out again\n","with open('ssd_v2_support.json', 'w') as file:\n","  file.write(filedata)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dmI0ejFNiA7Y"},"source":["#CONVERT TF MODEL to OPEN VINO IRv10. saved in IRv10 directory or choose name\n","%cd \"/content/models/research/fine_tuned_model/\"\n","!source /opt/intel/openvino_2021/bin/setupvars.sh && \\\n","    python /opt/intel/openvino_2021/deployment_tools/model_optimizer/mo.py \\\n","    --input_model frozen_inference_graph.pb \\\n","    --input_shape [1,300,300,3] \\\n","    --tensorflow_object_detection_api_pipeline_config pipeline.config \\\n","    --reverse_input_channels \\\n","    --output_dir ./IR_V10_fruits_mnssdv2_6k \\\n","    --data_type FP16"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nB6vH7ctiKJ7"},"source":["### New option"]},{"cell_type":"code","metadata":{"id":"6btvWtPHXC7r"},"source":["%cd /opt/intel/openvino_2021/deployment_tools/model_optimizer/extensions/front/tf/\n","#openvino fixes: edit \n","# Read in the file, make sure the .json corresponds to the model!!!\n","with open('ssd_v2_support.json', 'r') as file :\n","  filedata = file.read()\n","\n","# Replace the target string\n","filedata = filedata.replace('\"Postprocessor/ToFloat\"', '\"Postprocessor/Cast_1\"')\n","\n","# Write the file out again\n","with open('ssd_v2_support.json', 'w') as file:\n","  file.write(filedata)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AyUpvyCLGGsy"},"source":["source_cmd= \"/opt/intel/openvino_2021/bin/setupvars.sh\"\n","\n","%cd \"/content/models/research/fine_tuned_model/\"\n","\n","# Setup model optimizer command ...\n","ir_name = \"bee_detection\"\n","ir_data_type = \"FP16\"\n","ir_out_dir = f\"/content/IR_models/{ir_data_type}\"\n","ir_input_shape = \"[1,300,300,3]\"\n","model_fname = \"/content/models/research/fine_tuned_model/\"\n","\n","if selected_model == 'ssd_mobilenet_v2':\n","    !source /opt/intel/openvino_2021/bin/setupvars.sh && \\\n","        python /opt/intel/openvino_2021/deployment_tools/model_optimizer/mo.py \\\n","        --input_model frozen_inference_graph.pb \\\n","        --input_shape [1,300,300,3] \\\n","        --tensorflow_object_detection_api_pipeline_config pipeline.config \\\n","        --reverse_input_channels \\\n","        --output_dir {ir_out_dir} \\\n","        --data_type FP16 \\\n","        --input image_tensor \\\n","        --output detection_classes,detection_scores,detection_boxes,num_detections \\\n","        --tensorflow_use_custom_operations_config /opt/intel/openvino_2021/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json\n","\n","if selected_model == 'ssd_resnet_50':\n","    !source /opt/intel/openvino_2021/bin/setupvars.sh && \\\n","        python /opt/intel/openvino_2021/deployment_tools/model_optimizer/mo.py \\\n","        --input_model frozen_inference_graph.pb \\\n","        --input_shape [1,640,640,3] \\\n","        --tensorflow_object_detection_api_pipeline_config pipeline.config \\\n","        --reverse_input_channels \\\n","        --output_dir {ir_out_dir} \\\n","        --data_type FP16 \\\n","        --input image_tensor \\\n","        --output detection_classes,detection_scores,detection_boxes,num_detections \\\n","        --tensorflow_use_custom_operations_config /opt/intel/openvino_2021/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json\n","\n","mo_cmd = f\"/opt/intel/openvino_2021/deployment_tools/model_optimizer/mo_tf.py \\\n","      --saved_model_dir {model_fname} \\\n","      --input_shape {ir_input_shape} \\\n","      --data_type {ir_data_type} \\\n","      --output_dir {ir_out_dir}  \\\n","      --model_name {ir_name}\\\n","      --reverse_input_channels\\\n","      --input image_tensor\\\n","      --tensorflow_object_detection_api_pipeline_config pipeline.config\\\n","      --output detection_classes,detection_scores,detection_boxes,num_detections \"\n","#print (\"Running model optimizer to convert model to OpenVINO IR format ....\")\n","#print(\"\\n--\".join(mo_cmd.split(\"--\")))\n","\n","#output = subprocess.check_output(source_cmd+\" && \"+mo_cmd, shell=True)\n","#print (output.decode('utf-8'))     "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cj3g2GPIGjaB"},"source":["## Convert OpenVINO IR to Blob format "]},{"cell_type":"code","metadata":{"id":"P22MCwcbGkHp"},"source":["!cp /opt/intel/openvino_2021.2.200/deployment_tools/inference_engine/lib/intel64/libmyriadPlugin.so /usr/lib/x86_64-linux-gnu/libmyriadPlugin.so\n","#!source /opt/intel/openvino_2021/bin/setupvars.sh && /opt/intel/openvino_2021/deployment_tools/inference_engine/lib/intel64/myriad_compile -m {ir_out_dir}/frozen_inference_graph.xml -ip U8 -VPU_NUMBER_OF_SHAVES 4 -VPU_NUMBER_OF_CMX_SLICES 4\n","!source /opt/intel/openvino_2021/bin/setupvars.sh && /opt/intel/openvino_2021/deployment_tools/inference_engine/lib/intel64/myriad_compile -m {ir_out_dir}/frozen_inference_graph.xml -ip U8 -VPU_NUMBER_OF_SHAVES 10 -VPU_NUMBER_OF_CMX_SLICES 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zq3c3-16Hlt7"},"source":["!ls /content/IR_models/FP32/\n","#download the blob file to local directory.\n","from google.colab import files\n","files.download(f\"{ir_out_dir}/frozen_inference_graph.blob\")\n","\n","#if you want everything - uncomment these two lines\n","#!zip -r flower.zip flower \n","#files.download('flower.zip')"],"execution_count":null,"outputs":[]}]}