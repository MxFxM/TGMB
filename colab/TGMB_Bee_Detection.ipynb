{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Full_Bee_Detection.ipynb","private_outputs":true,"provenance":[{"file_id":"1XCns2AJ9vmfnVphNy5r-wEgY3d2B6DZj","timestamp":1618947684349},{"file_id":"https://github.com/luxonis/depthai-ml-training/blob/master/colab-notebooks/Easy_Object_Detection_Demo_Training.ipynb","timestamp":1616697584349}],"collapsed_sections":["qnIuC4b5g0Cw","GaNdvTclg2mP","yhzxsJb3dpWq","RcRKmaSbjUu4","H8eX04Mpjw9Q","ZFtQ0Ohuj3Qu","4MnKJP2yj9KC","Io8j9QEvkGPy","bI8__uNS8-ns","u-k7uGThXlny","iCNYAaC7w6N8","MvwtHlLOeRJD","SMio6Vwwmwga","CGyy24nLm1eP","JDddx2rPfex9","Kfjw6q-3wP62","RWsIs4E5nvD5","OmSESMetj1sa","-Wu5za9YFhQa","6_Y7vBE0p_eH","b5Z1QFooGIW8","cj3g2GPIGjaB","RfNZ5yT8rEdT"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"qnIuC4b5g0Cw"},"source":["# Sources"]},{"cell_type":"markdown","metadata":{"id":"gjj4axZVg5vK"},"source":["After way too much struggle and googeling, I finally found this:\n","\n","https://colab.research.google.com/github/luxonis/depthai-ml-training/blob/master/colab-notebooks/Easy_Object_Detection_With_Custom_Data_Demo_Training.ipynb"]},{"cell_type":"markdown","metadata":{"id":"GaNdvTclg2mP"},"source":["# While Hack"]},{"cell_type":"code","metadata":{"id":"p77QHgKKtdDm"},"source":["while True:\n","    pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yhzxsJb3dpWq"},"source":["# Install Libraries"]},{"cell_type":"code","metadata":{"id":"pH1x08R-yM-L"},"source":["# %%capture\n","\n","#After this cell executes runtime will restart, ignore the crash message, continue running cells starting with the one below\n","\n","# a specific numpy version is installed\n","!pip install numpy==1.17.5;\n","\n","# the runtime has to be crased (to be restarted to laod the new version)\n","\n","# !pip install tensorflow-gpu==1.15.0;\n","import os\n","os.kill(os.getpid(), 9)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9z8kgcs0E7iV"},"source":["# use the tensorflow version 1 (instead of 2 default)\n","%tensorflow_version 1.x\n","\n","!pip install tf_slim"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RcRKmaSbjUu4"},"source":["# Select a base model"]},{"cell_type":"code","metadata":{"id":"gnNXNQCjdniL"},"source":["# For faster training time, images should be resized to 300x300 and then annotated\n","# Images should contain the objects of interest at various scales, angles, lighting conditions, locations\n","\n","# a step means using a single batch of data\n","# larger batch, less steps required\n","num_steps = 1000\n","\n","# number of evaluation steps\n","num_eval_steps = 50\n","\n","# batch size 24 is a setting that generally works well\n","# can be changed higher or lower, depending on model size and available VRAM \n","# here some general information is stored in a dictionary\n","# one of the models can then be selected\n","MODELS_CONFIG = {\n","        'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n","        'batch_size': 32 #24\n","    },\n","        'ssd_resnet_50': {\n","        'model_name': 'ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03',\n","        'pipeline_file': 'ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync.config',\n","        'batch_size': 8\n","    },\n","        'ssd_inception_v2': {\n","        'model_name': 'ssd_inception_v2_coco_2018_01_28',\n","        'pipeline_file': 'ssd_inception_v2_coco.config',\n","        'batch_size': 32\n","    }\n","}\n","\n","# select one of the models to be used as the base model\n","# using transfer learning, the model will be retrained to suit your specific needs\n","selected_model = 'ssd_mobilenet_v2'\n","#selected_model = 'ssd_resnet_50'\n","#selected_model = 'ssd_inception_v2'\n","\n","# name of the object detection model to use.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","# name of the pipline file in tensorflow object detection API.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","# training batch size fits in Colab's GPU memory for selected model.\n","batch_size = MODELS_CONFIG[selected_model]['batch_size']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w4V-XE6kbkc1"},"source":["## Clone the `object_detection_demo_flow` repository"]},{"cell_type":"code","metadata":{"id":"dxc3DmvLQF3z"},"source":["repo_url = 'https://github.com/GotG/object_detection_demo_flow'\n","import os\n","\n","# escape the notebook with %\n","%cd /content\n","\n","repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n","\n","# escape the notebook with !\n","# clone the repository\n","!git clone {repo_url}\n","%cd {repo_dir_path}\n","\n","# get new changes\n","!git pull"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5oD4ASQ5jtyX"},"source":["## Upload your files"]},{"cell_type":"markdown","metadata":{"id":"H8eX04Mpjw9Q"},"source":["### Old option: Upload the files every time"]},{"cell_type":"code","metadata":{"id":"Sp0iUavswF9I"},"source":["from google.colab import files\n","\n","%cd /content\n","print(\"Upload the allimages.zip file\")\n","files.upload()\n","\n","!unzip allimages.zip -d ./allimages"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rbvx6X-PyNzv"},"source":["%cd /content\n","\n","# clear original images\n","!rm object_detection_demo_flow/test/*\n","!rm object_detection_demo_flow/data/images/train/*\n","!rm object_detection_demo_flow/data/images/test/*\n","!rm object_detection_demo_flow/data/images/final_test/*\n","\n","# instead, copy my images :D\n","!cp allimages/* object_detection_demo_flow/data/images/train/\n","!cp allimages/* object_detection_demo_flow/data/images/test/\n","!cp allimages/* object_detection_demo_flow/data/images/final_test/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZFtQ0Ohuj3Qu"},"source":["### New option: have dataset on Google Drive"]},{"cell_type":"markdown","metadata":{"id":"4MnKJP2yj9KC"},"source":["#### Prepare dataset\n","\n","One time setup."]},{"cell_type":"code","metadata":{"id":"HgG6aaafDfio"},"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VKojaxH3D2gU"},"source":["\"\"\"\n","%cd /content\n","\n","# clear original images\n","!rm object_detection_demo_flow/test/*\n","!rm object_detection_demo_flow/data/images/train/*\n","!rm object_detection_demo_flow/data/images/test/*\n","!rm object_detection_demo_flow/data/images/final_test/*\n","\n","!mkdir allimages\n","\n","import glob, os\n","from shutil import copyfile\n","os.chdir(\"/content/gdrive/MyDrive/TGMB/datasets/to-bee-or-not-to-bee/labels\")\n","for file in glob.glob(\"*.xml\"):\n","    #print(file)\n","    copyfile(f\"/content/gdrive/MyDrive/TGMB/datasets/to-bee-or-not-to-bee/allimages/{file[:-4]}.jpg\", f\"/content/allimages/{file[:-4]}.jpg\")\n","!cp /content/gdrive/MyDrive/TGMB/datasets/to-bee-or-not-to-bee/labels/* /content/allimages/\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"viUNOPQaGTrL"},"source":["\"\"\"\n","%cd /content\n","!mkdir /content/gdrive/MyDrive/TGMB/datasets/to-bee-or-not-to-bee/1000images\n","\n","# instead, copy my images :D\n","!cp allimages/* object_detection_demo_flow/data/images/train/\n","!cp allimages/* object_detection_demo_flow/data/images/test/\n","!cp allimages/* object_detection_demo_flow/data/images/final_test/\n","!cp allimages/* /content/gdrive/MyDrive/TGMB/datasets/to-bee-or-not-to-bee/1000images/\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Io8j9QEvkGPy"},"source":["### Load the dataset"]},{"cell_type":"markdown","metadata":{"id":"dyhYEK9IkNJD"},"source":["First mount Google Drive, where the dataset lives.\n","\n","The connection to Google Drive is slower than to the runtime itself.\n","That is why the images are copied over initially once."]},{"cell_type":"code","metadata":{"id":"kWvuI15XHZ2c"},"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")\n","\n","%cd /content\n","!mkdir allimages\n","!cp /content/gdrive/MyDrive/TGMB/datasets/to-bee-or-not-to-bee/1000images/* /content/allimages/\n","\n","# clear original images\n","!rm object_detection_demo_flow/test/*\n","!rm object_detection_demo_flow/data/images/train/*\n","!rm object_detection_demo_flow/data/images/test/*\n","!rm object_detection_demo_flow/data/images/final_test/*\n","\n","# instead, copy my images :D\n","!cp allimages/* object_detection_demo_flow/data/images/train/\n","\n","# note that it is really bad practice to have the same images for training and testing\n","# but we want a working result as fast as possible\n","# the accuracy does not matter at first\n","!cp allimages/* object_detection_demo_flow/data/images/test/\n","!cp allimages/* object_detection_demo_flow/data/images/final_test/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bI8__uNS8-ns"},"source":["## Clone TF models which contains the Object Detection API; also install the required dependencies\n"]},{"cell_type":"code","metadata":{"id":"ecpHEnka8Kix"},"source":["%%capture\n","%cd /content\n","!git clone --quiet https://github.com/tensorflow/models.git\n","%cd /content/models/\n","!git checkout 58d19c67e1d30d905dd5c6e5092348658fed80af\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n","!pip install -q Cython contextlib2 pillow lxml matplotlib\n","!pip install -q pycocotools\n","%cd /content/models/research\n","!protoc object_detection/protos/*.proto --python_out=.\n","import os\n","os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n","!python object_detection/builders/model_builder_test.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u-k7uGThXlny"},"source":["## Prepare `tfrecord` files\n","\n"]},{"cell_type":"code","metadata":{"id":"ezGDABRXXhPP"},"source":["%%capture\n","%cd {repo_dir_path}\n","\n","# Convert train folder annotation xml files to a single csv file,\n","# generate the `label_map.pbtxt` file to `data/` directory as well.\n","!python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n","\n","# Convert test folder annotation xml files to a single csv.\n","!python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n","\n","# Generate `train.record`\n","!python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n","\n","# Generate `test.record`\n","!python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tgd-fzAIkZlV"},"source":["test_record_fname = '/content/object_detection_demo_flow/data/annotations/test.record'\n","train_record_fname = '/content/object_detection_demo_flow/data/annotations/train.record'\n","label_map_pbtxt_fname = '/content/object_detection_demo_flow/data/annotations/label_map.pbtxt'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iCNYAaC7w6N8"},"source":["## Download the Model, depending on selection"]},{"cell_type":"code","metadata":{"id":"orDCj6ihgUMR"},"source":["%cd /content/models/research\n","\n","import os\n","import shutil\n","import glob\n","import urllib.request\n","import tarfile\n","MODEL_FILE = MODEL + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","DEST_DIR = '/content/models/research/pretrained_model'\n","\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","# untar the downloaded file\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","# remove the tar\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","    shutil.rmtree(DEST_DIR)\n","\n","os.rename(MODEL, DEST_DIR)\n","!echo {DEST_DIR}\n","!ls -alh {DEST_DIR}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UHnxlfRznPP3"},"source":["#TF pretrained model checkpoint\n","fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n","fine_tune_checkpoint"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MvwtHlLOeRJD"},"source":["## Configuring a Training Pipeline"]},{"cell_type":"code","metadata":{"id":"dIhw7IdpLuiU"},"source":["import os\n","pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n","\n","# check if the configuration file exists\n","assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)\n","\n","# function to get the number of classes\n","def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    # load the label map\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    # get the categories ffrom the map\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    # index the categories\n","    category_index = label_map_util.create_category_index(categories)\n","    # return the length (number of unique ids)\n","    return len(category_index.keys())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SMio6Vwwmwga"},"source":["### ResNet 50 handling"]},{"cell_type":"markdown","metadata":{"id":"kg1oh1BsldVN"},"source":["In case the ResNet 50 was selected as the base model, an updated configuration file has to be used.\n","\n","Read the full documentation on [GitHub](https://github.com/MxFxM/TGMB) to find out what to change."]},{"cell_type":"code","metadata":{"id":"EFMJBsTbcCcp"},"source":["if selected_model == 'ssd_resnet_50':\n","    print(\"Upload ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync.config now\")\n","    from google.colab import files\n","    files.upload()\n","    !cp /content/models/research/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync.config /content/models/research/object_detection/samples/configs/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync.config\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CGyy24nLm1eP"},"source":["## Overwrite default pipeline values"]},{"cell_type":"code","metadata":{"id":"YjtCbLF2i0wI"},"source":["import re\n","iou_threshold = 0.50\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n","\n","# reat the old file\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","\n","# by substitutions, enter the new values\n","with open(pipeline_fname, 'w') as f:\n","    \n","    # fine_tune_checkpoint\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # tfrecord files train and test.\n","    s = re.sub(\n","        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    # Set number of classes num_classes.\n","    s = re.sub('iou_threshold: [0-9].[0-9]+',\n","               'iou_threshold: {}'.format(iou_threshold), s)\n","    \n","    f.write(s)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JDddx2rPfex9"},"source":["# Train the model"]},{"cell_type":"markdown","metadata":{"id":"Kfjw6q-3wP62"},"source":["## Start the training"]},{"cell_type":"code","metadata":{"id":"CjDHjhKQofT5"},"source":["# note that training is stored in /content/models/research/training/\n","model_dir = 'training/'\n","\n","# os.makedirs(model_dir, exist_ok=True)\n","\n","# this is all, the rest is handled by the API\n","!python -W ignore /content/models/research/object_detection/model_main.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --num_eval_steps={num_eval_steps}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RWsIs4E5nvD5"},"source":["## Check the output in the model directory"]},{"cell_type":"code","metadata":{"id":"KP-tUdtnRybs"},"source":["# model dir check for the trained model\n","!ls {model_dir}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OmSESMetj1sa"},"source":["## Export a Trained Inference Graph\n","Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"]},{"cell_type":"code","metadata":{"id":"zZJ_AF5MD3hZ"},"source":["#clean output_directory if necessary to start fresh:\n","\n","# !rm -rf /content/object_detection_demo/fine_tuned_model/ \n","# os.makedirs('/content/object_detection_demo_flow/fine_tuned_model/', exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XuBh5fJ8odo7"},"source":["The frozen inference graph \"freezes\" the model at a certain state.\n","This state can be used to compile the blob file with OpenVINO, or as a general method of storing the model."]},{"cell_type":"code","metadata":{"id":"DHoP90pUyKSq"},"source":["%%capture\n","import re\n","import numpy as np\n","\n","output_directory = './fine_tuned_model'\n","\n","# list all files in the checkpoint directory\n","lst = os.listdir(model_dir)\n","\n","# keep only the ones that end on .meta\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n","\n","# find the number of steps (it is in the filename of the checkpoint)\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","\n","# get the chekcopoint with the largest number of steps\n","last_model = lst[steps.argmax()].replace('.meta', '')\n","\n","last_model_path = os.path.join(model_dir, last_model)\n","print(last_model_path)\n","\n","# export that checkpoint as the frozen inference graph\n","!python /content/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --output_directory={output_directory} \\\n","    --trained_checkpoint_prefix={last_model_path}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CnDo1lonKgFr"},"source":["import os\n","pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n","\n","# check for the file\n","# if it does not exist, the export has failed\n","assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)\n","\n","# !ls -alh {pb_fname}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Wu5za9YFhQa"},"source":["# Intel OpenVINO toolkit Installation and Validations 2021"]},{"cell_type":"markdown","metadata":{"id":"6_Y7vBE0p_eH"},"source":["## Installation"]},{"cell_type":"markdown","metadata":{"id":"4ZjkqB6MqBJM"},"source":["No questions asked for the OpenVINO installation. It works, that is all that is important."]},{"cell_type":"code","metadata":{"id":"i8Ck5LpKhBil"},"source":["!cd /content"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fk0YYXXdFzPj"},"source":["print(\"This will take a while...\")\n","!wget -O openvino_key https://apt.repos.intel.com/openvino/2021/GPG-PUB-KEY-INTEL-OPENVINO-2021?elq_cid=6770273_ts1607381885691&erpm_id=9830841_ts1607381885691&elq_cid=6770273_ts1607381960247&erpm_id=9830841_ts1607381960247 \n","!apt-key add openvino_key\n","#!apt-key -q list\n","!echo \"deb https://apt.repos.intel.com/openvino/2021 all main\" | tee /etc/apt/sources.list.d/intel-openvino-2021.list\n","!apt update -q\n","!apt-cache search intel-openvino-dev-ubuntu18\n","!apt-get install intel-openvino-dev-ubuntu18-2021.2.200 -y -q\n","!pip install -U --no-deps --quiet openvino\n","\n","#unknown bug - this is just a patch\n","!cp /opt/intel/openvino_2021/deployment_tools/inference_engine/external/tbb/lib/libtbb.so /usr/lib/x86_64-linux-gnu/libtbb.so\n","!cp /opt/intel/openvino_2021/deployment_tools/inference_engine/external/tbb/lib/libtbb.so.2 /usr/lib/x86_64-linux-gnu/libtbb.so.2\n","!ldconfig\n","print(\"Installation Completed...\")\n","#%env we can set environmental variable with this\n","\n","#Run the validation\n","!ls /opt/intel/\n","#Run the Validation Demo code.\n","demo_cmd = \"/opt/intel/openvino_2021/deployment_tools/demo/demo_squeezenet_download_convert_run.sh\"\n","import os\n","import subprocess\n","import shutil\n","output = subprocess.check_output(demo_cmd, shell=True)\n","print (output.decode('utf-8'))     "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b5Z1QFooGIW8"},"source":["## Convert to OpenVINO IR format"]},{"cell_type":"markdown","metadata":{"id":"twZrkrWbqHKi"},"source":["There is a small manual change in the support file, necessary when compiling some of the models."]},{"cell_type":"code","metadata":{"id":"6btvWtPHXC7r"},"source":["%cd /opt/intel/openvino_2021/deployment_tools/model_optimizer/extensions/front/tf/\n","#openvino fixes: edit \n","# Read in the file, make sure the .json corresponds to the model!!!\n","with open('ssd_v2_support.json', 'r') as file :\n","  filedata = file.read()\n","\n","# Replace the target string\n","filedata = filedata.replace('\"Postprocessor/ToFloat\"', '\"Postprocessor/Cast_1\"')\n","\n","# Write the file out again\n","with open('ssd_v2_support.json', 'w') as file:\n","  file.write(filedata)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xmiAIkG0qPF2"},"source":["Each model has its own configuration used for the model optimizer.\n","\n","To find your options (arguments), head over to the [OpenVINO Model Zoo](https://github.com/openvinotoolkit/open_model_zoo) and check the model.yml file for your specific base model."]},{"cell_type":"code","metadata":{"id":"AyUpvyCLGGsy"},"source":["source_cmd= \"/opt/intel/openvino_2021/bin/setupvars.sh\"\n","\n","%cd \"/content/models/research/fine_tuned_model/\"\n","\n","# Setup model optimizer command ...\n","ir_name = \"bee_detection\"\n","\n","# data type\n","ir_data_type = \"FP16\"\n","\n","# output directory\n","ir_out_dir = f\"/content/IR_models/{ir_data_type}\"\n","\n","# input shape (might be overwritten depending on the base model)\n","ir_input_shape = \"[1,300,300,3]\"\n","\n","model_fname = \"/content/models/research/fine_tuned_model/\"\n","\n","if selected_model == 'ssd_mobilenet_v2':\n","    !source /opt/intel/openvino_2021/bin/setupvars.sh && \\\n","        python /opt/intel/openvino_2021/deployment_tools/model_optimizer/mo.py \\\n","        --input_model frozen_inference_graph.pb \\\n","        --input_shape [1,300,300,3] \\\n","        --tensorflow_object_detection_api_pipeline_config pipeline.config \\\n","        --reverse_input_channels \\\n","        --output_dir {ir_out_dir} \\\n","        --data_type FP16 \\\n","        --input image_tensor \\\n","        --output detection_classes,detection_scores,detection_boxes,num_detections \\\n","        --tensorflow_use_custom_operations_config /opt/intel/openvino_2021/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json\n","\n","if selected_model == 'ssd_resnet_50':\n","    !source /opt/intel/openvino_2021/bin/setupvars.sh && \\\n","        python /opt/intel/openvino_2021/deployment_tools/model_optimizer/mo.py \\\n","        --input_model frozen_inference_graph.pb \\\n","        --input_shape [1,640,640,3] \\\n","        --tensorflow_object_detection_api_pipeline_config pipeline.config \\\n","        --reverse_input_channels \\\n","        --output_dir {ir_out_dir} \\\n","        --data_type FP16 \\\n","        --input image_tensor \\\n","        --output detection_classes,detection_scores,detection_boxes,num_detections \\\n","        --tensorflow_use_custom_operations_config /opt/intel/openvino_2021/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cj3g2GPIGjaB"},"source":["## Convert OpenVINO IR to Blob format "]},{"cell_type":"markdown","metadata":{"id":"q1hUkdfUrCSY"},"source":["Then the IR file can be converted to the blob file.\n","\n","The number of shaves can be adjusted.\n","The OAK-D has 16 shaves in total, 13 can be used when the main camera is in 1080P mode and 10 when the camera runs in 4K mode.\n","The remaining shaves can be split up into the models that have to run simultaneously on the same pipeline."]},{"cell_type":"code","metadata":{"id":"P22MCwcbGkHp"},"source":["!cp /opt/intel/openvino_2021.2.200/deployment_tools/inference_engine/lib/intel64/libmyriadPlugin.so /usr/lib/x86_64-linux-gnu/libmyriadPlugin.so\n","#!source /opt/intel/openvino_2021/bin/setupvars.sh && /opt/intel/openvino_2021/deployment_tools/inference_engine/lib/intel64/myriad_compile -m {ir_out_dir}/frozen_inference_graph.xml -ip U8 -VPU_NUMBER_OF_SHAVES 4 -VPU_NUMBER_OF_CMX_SLICES 4\n","!source /opt/intel/openvino_2021/bin/setupvars.sh && /opt/intel/openvino_2021/deployment_tools/inference_engine/lib/intel64/myriad_compile -m {ir_out_dir}/frozen_inference_graph.xml -ip U8 -VPU_NUMBER_OF_SHAVES 10 -VPU_NUMBER_OF_CMX_SLICES 10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RfNZ5yT8rEdT"},"source":["## Download blob file"]},{"cell_type":"code","metadata":{"id":"zq3c3-16Hlt7"},"source":["from google.colab import files\n","\n","#download the blob file to local directory\n","files.download(f\"{ir_out_dir}/frozen_inference_graph.blob\")"],"execution_count":null,"outputs":[]}]}